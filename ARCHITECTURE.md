# SMARTACUS â€” Document d'Architecture Complet

> **Version** : 1.1
> **Date** : 5 fÃ©vrier 2026
> **Statut** : Run 1 validÃ© (100 ASINs, 0 erreurs, DQ PASS)

---

## Table des matiÃ¨res

1. [Vue d'ensemble](#1-vue-densemble)
2. [Architecture systÃ¨me](#2-architecture-systÃ¨me)
3. [Stack technique](#3-stack-technique)
4. [Structure du projet](#4-structure-du-projet)
5. [Couche DonnÃ©es (src/data)](#5-couche-donnÃ©es-srcdata)
6. [Moteur de Scoring (src/scoring)](#6-moteur-de-scoring-srcscoring)
7. [API REST (src/api)](#7-api-rest-srcapi)
8. [Frontend (web/)](#8-frontend-web)
9. [Base de donnÃ©es](#9-base-de-donnÃ©es)
10. [Pipeline d'ingestion](#10-pipeline-dingestion)
11. [DÃ©tection d'Ã©vÃ©nements](#11-dÃ©tection-dÃ©vÃ©nements)
12. [IA et Agents](#12-ia-et-agents)
13. [RAG (Retrieval-Augmented Generation)](#13-rag-retrieval-augmented-generation)
14. [Orchestration & Monitoring](#14-orchestration--monitoring)
15. [Flux de donnÃ©es complet](#15-flux-de-donnÃ©es-complet)
16. [SÃ©curitÃ© & Configuration](#16-sÃ©curitÃ©--configuration)
17. [Performance & Optimisations](#17-performance--optimisations)
18. [DÃ©cisions architecturales](#18-dÃ©cisions-architecturales)
19. [RÃ©sultats Run 1](#19-rÃ©sultats-run-1)
20. [Roadmap](#20-roadmap)

---

## 1. Vue d'ensemble

**Smartacus** est une sonde Ã©conomique Amazon qui dÃ©tecte automatiquement les opportunitÃ©s de marchÃ© dans la niche *Car Phone Mounts*. Le systÃ¨me collecte des donnÃ©es produit via l'API Keepa, calcule un score d'opportunitÃ© dÃ©terministe, et prÃ©sente les rÃ©sultats via une interface web interactive.

### Proposition de valeur

```
DonnÃ©es Keepa â†’ Scoring dÃ©terministe â†’ Classement par valeur Ã— urgence â†’ DÃ©cision utilisateur
```

### Principes fondamentaux

| Principe | ImplÃ©mentation |
|----------|---------------|
| **100% dÃ©terministe** | Scoring sans ML, entiÃ¨rement explicable |
| **Le temps est un multiplicateur** | Score Ã— TimeMultiplier, pas un simple composant additif |
| **Audit trail complet** | Chaque run enregistrÃ© avec mÃ©triques, timing, erreurs |
| **Freeze mode** | Scoring sans promotion en shortlist (observation) |
| **Fallback gracieux avec garde-fous** | DonnÃ©es mock si API/DB indisponibles, mais actions (sourcing, export, IA) **dÃ©sactivÃ©es** en mode DEMO. BanniÃ¨re + watermark explicites |
| **DÃ©cisionnel cÃ´tÃ© backend** | Les utilisateurs ne voient que les articles proposÃ©s |

---

## 2. Architecture systÃ¨me

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         UTILISATEUR                              â”‚
â”‚                    http://localhost:3000                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js 14)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Dashboard â”‚  â”‚ Detail Panel â”‚  â”‚ Filters  â”‚  â”‚ Agent Chat â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    Proxy /api/* â†’ :8000                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST API
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (FastAPI + Uvicorn)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ShortlistSvc â”‚  â”‚ PipelineSvc    â”‚  â”‚ AI Agents          â”‚   â”‚
â”‚  â”‚ (DB â†’ API)   â”‚  â”‚ (Run tracking) â”‚  â”‚ (Claude/OpenAI)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                  â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  DB Connection Pool                        â”‚  â”‚
â”‚  â”‚              (psycopg2 ThreadedPool)                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ PostgreSQL Wire Protocol (SSL)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RAILWAY POSTGRESQL 17.7                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ asins  â”‚ â”‚asin_snapshotsâ”‚ â”‚ *_events  â”‚ â”‚opportunity_      â”‚ â”‚
â”‚  â”‚ (108)  â”‚ â”‚    (108)     â”‚ â”‚ (triggers)â”‚ â”‚artifacts (100)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚pipeline_runs â”‚  â”‚ mat viewsâ”‚  â”‚  4 triggers auto-events   â”‚ â”‚
â”‚  â”‚    (13)      â”‚  â”‚   (4)    â”‚  â”‚  3 views, 92+ indexes     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚ Batch Ingestion (scripts/)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PIPELINE CLI (run_controlled.py)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Discoveryâ”‚â†’ â”‚  Fetch   â”‚â†’ â”‚DB Insertâ”‚â†’ â”‚ Score â”‚â†’ â”‚ Audit â”‚ â”‚
â”‚  â”‚ (Keepa)  â”‚  â”‚ (Keepa)  â”‚  â”‚(triggersâ”‚  â”‚(econ) â”‚  â”‚(JSON) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ fire)   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST API
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       KEEPA API                                  â”‚
â”‚           21 tokens/min | Discovery + Product queries            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Stack technique

| Couche | Technologies | Version |
|--------|-------------|---------|
| **Frontend** | Next.js, React, TypeScript, Tailwind CSS | 14.2, 18.3 |
| **Backend API** | FastAPI, Uvicorn, Pydantic | 0.109+ |
| **Scoring** | Python pur (pas de ML) | 3.12 |
| **Data** | Keepa API, psycopg2, NumPy, Pandas | keepa 1.4.3 |
| **Database** | PostgreSQL (Railway) | 17.7 |
| **Extensions DB** | pg_trgm, btree_gin | natif |
| **LLM** | Anthropic Claude, OpenAI | claude-3-opus |
| **CLI** | argparse, tqdm, rich | stdlib |
| **Tests** | pytest, pytest-cov | 7.4+ |

### DÃ©pendances principales (requirements.txt)

```
# Core
keepa>=1.3.0
psycopg2-binary>=2.9.9
python-dotenv>=1.0.0
pydantic>=2.5.0
numpy>=1.24.0

# Web
fastapi>=0.109.0
uvicorn[standard]>=0.27.0

# LLM
anthropic>=0.40.0
openai>=1.50.0

# Data
requests>=2.31.0
aiohttp>=3.9.0
python-dateutil>=2.8.2

# Ops
structlog>=23.2.0
prometheus-client>=0.19.0
schedule>=1.2.0
tqdm>=4.66.0
```

---

## 4. Structure du projet

```
smartacus/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                          # Couche donnÃ©es
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_models.py            # 462 lignes â€” ModÃ¨les Python (ProductData, Snapshot, etc.)
â”‚   â”‚   â”œâ”€â”€ keepa_client.py           # 1069 lignes â€” Client Keepa avec rate limiting
â”‚   â”‚   â”œâ”€â”€ config.py                 # 295 lignes â€” Configuration centralisÃ©e
â”‚   â”‚   â””â”€â”€ ingestion_pipeline.py     # 894 lignes â€” Pipeline d'ingestion
â”‚   â”‚
â”‚   â”œâ”€â”€ scoring/                       # Moteur de scoring
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scoring_config.py         # 375 lignes â€” Seuils et poids
â”‚   â”‚   â”œâ”€â”€ opportunity_scorer.py     # 915 lignes â€” Scoring 5 composantes
â”‚   â”‚   â”œâ”€â”€ economic_scorer.py        # 495 lignes â€” Score Ã— multiplicateur temps
â”‚   â”‚   â””â”€â”€ calibration.py            # 402 lignes â€” Calibration et backtesting
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                           # API REST
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                   # 416 lignes â€” FastAPI app + endpoints
â”‚   â”‚   â”œâ”€â”€ models.py                 # 180 lignes â€” ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ services.py              # 731 lignes â€” Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ db.py                     # 314 lignes â€” Pool connexions PostgreSQL
â”‚   â”‚   â”œâ”€â”€ ai_routes.py             # 369 lignes â€” Endpoints IA
â”‚   â”‚   â””â”€â”€ rag_routes.py            # 292 lignes â€” Endpoints RAG
â”‚   â”‚
â”‚   â”œâ”€â”€ events/                        # DÃ©tection d'Ã©vÃ©nements
â”‚   â”‚   â”œâ”€â”€ economic_events.py        # 729 lignes â€” DÃ©tecteur d'Ã©vÃ©nements
â”‚   â”‚   â””â”€â”€ event_models.py           # 571 lignes â€” ModÃ¨les d'Ã©vÃ©nements
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                            # IntÃ©gration LLM
â”‚   â”‚   â”œâ”€â”€ llm_client.py            # 316 lignes â€” Client Claude
â”‚   â”‚   â”œâ”€â”€ thesis_generator.py       # 343 lignes â€” GÃ©nÃ©ration de thÃ¨ses
â”‚   â”‚   â”œâ”€â”€ review_analyzer.py        # 390 lignes â€” Analyse de reviews
â”‚   â”‚   â””â”€â”€ agents/                   # Agents IA
â”‚   â”‚       â”œâ”€â”€ base.py, discovery.py, analyst.py, sourcing.py, negotiator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                           # RAG Knowledge Base
â”‚   â”‚   â”œâ”€â”€ ingestion.py, chunker.py, embedder.py, retriever.py, models.py
â”‚   â”‚
â”‚   â””â”€â”€ orchestrator/                  # Orchestration
â”‚       â”œâ”€â”€ daily_pipeline.py, scheduler.py, shortlist.py
â”‚       â”œâ”€â”€ monitoring.py, state.py, logging_config.py
â”‚
â”œâ”€â”€ web/                               # Frontend Next.js
â”‚   â”œâ”€â”€ src/app/                       # Pages (App Router)
â”‚   â”œâ”€â”€ src/components/                # 6 composants React
â”‚   â”œâ”€â”€ src/lib/                       # API client, formatters, mock data
â”‚   â”œâ”€â”€ src/types/                     # Types TypeScript
â”‚   â””â”€â”€ src/hooks/                     # Custom hooks
â”‚
â”œâ”€â”€ scripts/                           # CLI
â”‚   â”œâ”€â”€ run_controlled.py             # 840 lignes â€” Pipeline contrÃ´lÃ© (Run 1)
â”‚   â”œâ”€â”€ run_ingestion.py              # 265 lignes â€” Ingestion quotidienne
â”‚   â”œâ”€â”€ test_keepa_connection.py      # 89 lignes â€” Test Keepa
â”‚   â””â”€â”€ test_pipeline_offline.py      # 227 lignes â€” Test offline
â”‚
â”œâ”€â”€ database/migrations/               # SchÃ©ma SQL
â”‚   â”œâ”€â”€ 001_railway_init.sql          # 859 lignes â€” SchÃ©ma complet
â”‚   â”œâ”€â”€ 002_pipeline_runs_and_dedup.sql
â”‚   â””â”€â”€ 003_quality_gates_and_artifacts.sql
â”‚
â”œâ”€â”€ data/                              # Sorties runtime
â”‚   â”œâ”€â”€ audit_run_*.json              # Audits de run
â”‚   â””â”€â”€ opportunities_run_*.json      # OpportunitÃ©s scorÃ©es
â”‚
â””â”€â”€ .env                               # Configuration (non versionnÃ©)
```

**Total** : ~12 000+ lignes Python + SQL + TypeScript

---

## 5. Couche DonnÃ©es (src/data)

### 5.1 ModÃ¨les de donnÃ©es (data_models.py)

```python
# HiÃ©rarchie des modÃ¨les
ProductData                    # Conteneur principal
â”œâ”€â”€ metadata: ProductMetadata  # â†’ table `asins`
â”œâ”€â”€ current_snapshot: ProductSnapshot  # â†’ table `asin_snapshots`
â”œâ”€â”€ price_history: List[PriceHistory]  # Pour analyse de tendance
â”œâ”€â”€ bsr_history: List[BSRHistory]      # Pour BSR trend
â””â”€â”€ buybox_history: List[BuyBoxHistory] # Pour rotation vendeurs
```

| Classe | RÃ´le | Table DB |
|--------|------|----------|
| `ProductMetadata` | Titre, marque, catÃ©gorie, images | `asins` |
| `ProductSnapshot` | Prix, BSR, stock, notes, vendeurs | `asin_snapshots` |
| `PriceHistory` | Historique prix (30j) | Analyse in-memory |
| `BSRHistory` | Historique BSR (30j) | Analyse in-memory |
| `StockStatus` | Enum: in_stock, low_stock, out_of_stock... | Type PostgreSQL |
| `FulfillmentType` | Enum: fba, fbm, amazon | Type PostgreSQL |

### 5.2 Client Keepa (keepa_client.py)

```python
class KeepaClient:
    """Client Keepa robuste avec rate limiting intelligent."""

    # Rate Limiting
    _rate_limit: RateLimitState  # Tokens tracking interne
    _rate_limit_lock: Lock       # Thread-safe

    # MÃ©thodes principales
    get_category_asins(category_id) â†’ List[str]     # ~5 tokens
    get_product_data(asins, include_history) â†’ List[ProductData]  # ~2 tokens/ASIN
    get_best_sellers(category_id) â†’ List[str]
    health_check() â†’ Dict
    get_stats() â†’ Dict  # tokens restants, requÃªtes, erreurs
```

**Quirks Keepa v1.4.3** :
- `keepa.KeepaError` n'existe PAS â†’ catch `Exception`
- `best_sellers_query(str(cat_id), domain='US')` pas `category_lookup`
- `api.query()` domain : string `'US'`, pas int `1`
- CSV data : numpy arrays shape (N,2) avec datetime+value
- `stats['current']` est une liste indexÃ©e par type de prix

### 5.3 Configuration (config.py)

```python
@dataclass(frozen=True)
class Settings:
    keepa: KeepaConfig        # API key, tokens/min, retries
    database: DatabaseConfig   # Host, port, pool, SSL
    ingestion: IngestionConfig # Category, batch_size, filtres
    logging: LoggingConfig     # Level, format, file
```

### 5.4 Pipeline d'ingestion (ingestion_pipeline.py)

```python
class IngestionPipeline:
    # DÃ©couverte
    discover_category_asins() â†’ List[str]          # Keepa best_sellers
    get_asins_needing_update(asins) â†’ List[str]    # Filtre fraÃ®cheur

    # Batch processing
    fetch_product_batch(asins) â†’ List[ProductData]  # Keepa product query
    upsert_asin_metadata(products) â†’ int            # INSERT/UPDATE asins
    insert_snapshots(products, session_id) â†’ int    # INSERT snapshots (triggers!)

    # Maintenance
    refresh_materialized_views()                     # REFRESH CONCURRENTLY
    close()                                          # Ferme pool DB
```

---

## 6. Moteur de Scoring (src/scoring)

### 6.1 Scoring de base (opportunity_scorer.py)

**Formule** : 5 composantes additives, 100 points max.

```
Score Total = Margin(30) + Velocity(25) + Competition(20) + Gap(15) + TimePressure(10)
```

| Composante | Max | Ce qu'elle mesure |
|-----------|-----|-------------------|
| **Margin** | 30 | Marge nette aprÃ¨s FBA fees, PPC, retours |
| **Velocity** | 25 | BSR absolu + deltas 7j/30j + reviews/mois |
| **Competition** | 20 | Nombre vendeurs FBA + rotation BuyBox |
| **Gap** | 15 | Gap reviews vs top 10 + % avis nÃ©gatifs |
| **TimePressure** | 10 | Ruptures stock + accÃ©lÃ©ration BSR + volatilitÃ© prix |

**RÃ¨gle critique** : `time_pressure < 3` â†’ rejet automatique (`invalid_no_window`)

### 6.2 Gating vs Ranking â€” deux rÃ´les du temps

Le scoring utilise le temps Ã  deux niveaux distincts, qu'il ne faut pas confondre :

| Concept | OÃ¹ | RÃ´le | Question posÃ©e |
|---------|-----|------|---------------|
| **TimePressure** (composante, 0-10) | `opportunity_scorer.py` | **Gating** : existe-t-il une fenÃªtre ? | "Y a-t-il une urgence qui rend cette opportunitÃ© actionnable ?" |
| **time_multiplier** (Ã—0.5â€“2.0) | `economic_scorer.py` | **Ranking** : Ã  quelle vitesse la fenÃªtre se ferme-t-elle ? | "Ã€ valeur Ã©gale, laquelle traiter en premier ?" |

- **TimePressure < 3** â†’ rejet. Le produit n'a aucun signal temporel exploitable (`invalid_no_window`).
- **time_multiplier** amplifie ou attÃ©nue la valeur Ã©conomique. Un produit score 65 avec fenÃªtre 14j (`Ã—1.5`) rank au-dessus d'un score 70 avec fenÃªtre 120j (`Ã—0.7`).

En rÃ©sumÃ© : **TimePressure filtre, time_multiplier priorise.**

### 6.3 Scoring Ã©conomique (economic_scorer.py)

**Formule** : base_score Ã— time_multiplier

```python
# Le temps N'EST PAS un composant additif
# Le temps EST un MULTIPLICATEUR de la valeur d'opportunitÃ©
final_score = int(base_score Ã— time_multiplier Ã— 100)  # [0-100]
```

**Multiplicateur temporel** : moyenne gÃ©omÃ©trique de 4 facteurs, clampÃ©e [0.5 â€“ 2.0]

```python
time_multiplier = (stockout_factor Ã— churn_factor Ã— volatility_factor Ã— bsr_factor) ^ 0.25
```

| Facteur | Seuils | Multiplicateur |
|---------|--------|---------------|
| Stockout freq | â‰¥3/mois â†’ 1.5, â‰¥1 â†’ 1.2, â‰¥0.5 â†’ 1.0, <0.5 â†’ 0.8 |
| Seller churn | >30% â†’ 1.4, >20% â†’ 1.2, >10% â†’ 1.0, <10% â†’ 0.8 |
| Price volatility | >20% â†’ 1.3, >10% â†’ 1.1, â‰¤10% â†’ 1.0 |
| BSR acceleration | >10% â†’ 1.4, >0% â†’ 1.2, >-5% â†’ 1.0, <-5% â†’ 0.8 |

### 6.4 FenÃªtres temporelles

| Window | Jours | Multiplicateur | Action |
|--------|-------|---------------|--------|
| CRITICAL | â‰¤14 | 2.0Ã— | Agir immÃ©diatement |
| URGENT | 14-30 | 1.5Ã— | Action prioritaire |
| ACTIVE | 30-60 | 1.2Ã— | FenÃªtre viable |
| STANDARD | 60-90 | 1.0Ã— | Temps disponible |
| EXTENDED | >90 | 0.7Ã— | Pas d'urgence |

### 6.5 Valeur Ã©conomique

```python
monthly_profit = (amazon_price - COGS - FBA_fees - referral - PPC - returns) Ã— monthly_units
annual_value = monthly_profit Ã— 12
risk_adjusted_value = annual_value Ã— 0.7
rank_score = risk_adjusted_value Ã— urgency_weight  # Pour le classement
```

---

## 7. API REST (src/api)

### 7.1 Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/health` | GET | SantÃ© DB + Keepa + dernier run |
| `/api/observability` | GET | MÃ©triques DB complÃ¨tes |
| `/api/shortlist` | GET | Top N opportunitÃ©s (DB â†’ demo fallback) |
| `/api/shortlist/export` | GET | Export CSV avec filtres |
| `/api/pipeline/status` | GET | Statut du pipeline |
| `/api/pipeline/run` | POST | Lancer un run pipeline |
| `/api/maintenance/cleanup` | POST | Nettoyage events + VACUUM |
| `/api/maintenance/refresh-views` | POST | Refresh mat views |
| `/api/ai/status` | GET | Statut services IA |
| `/api/ai/thesis` | POST | GÃ©nÃ©rer thÃ¨se Ã©conomique |
| `/api/ai/agent/present-opportunity` | POST | Initialiser conversation agent |
| `/api/ai/agent/message` | POST | Message Ã  un agent |

### 7.2 ShortlistService (services.py)

```python
class ShortlistService:
    def get_shortlist(max_items, min_score, min_value) â†’ ShortlistResponse:
        # 1. Essaie la DB (opportunity_artifacts)
        opportunities = self._get_db_opportunities(max_items, min_score, min_value)
        # 2. Fallback donnÃ©es demo si DB vide
        if not opportunities:
            opportunities = self._get_demo_opportunities(max_items)
        # 3. Construit la rÃ©ponse
        return ShortlistResponse(summary=..., opportunities=...)
```

### 7.3 ModÃ¨les Pydantic (models.py)

```python
class OpportunityModel(BaseModel):
    rank: int
    asin: str
    title: Optional[str]
    brand: Optional[str]
    finalScore: int           # alias: final_score
    baseScore: float          # alias: base_score
    timeMultiplier: float     # alias: time_multiplier
    estimatedMonthlyProfit: float
    estimatedAnnualValue: float
    riskAdjustedValue: float
    windowDays: int
    urgencyLevel: UrgencyLevel
    urgencyLabel: str
    thesis: str
    actionRecommendation: str
    componentScores: Dict[str, ComponentScoreModel]
    economicEvents: List[EconomicEventModel]
    amazonPrice: Optional[float]
    reviewCount: Optional[int]
    rating: Optional[float]
    detectedAt: datetime

    class Config:
        populate_by_name = True  # Accepte snake_case ET camelCase
```

### 7.4 Connexion DB (db.py)

```python
# Pool lazy singleton (psycopg2 ThreadedConnectionPool)
get_pool() â†’ ThreadedConnectionPool
get_connection() â†’ ContextManager  # with get_connection() as conn: ...

# OpÃ©rations
check_health() â†’ Dict
create_pipeline_run(triggered_by, config) â†’ str  # â†’ run_id
update_pipeline_run(run_id, status, metrics...)
get_latest_pipeline_run() â†’ Optional[Dict]
run_maintenance(retention_days) â†’ Dict
refresh_materialized_views() â†’ Dict
```

---

## 8. Frontend (web/)

### 8.1 Architecture

```
Next.js 14 (App Router)
â”œâ”€â”€ Layout (layout.tsx)           # HTML shell
â”œâ”€â”€ Page (page.tsx)               # Dashboard principal
â”‚   â”œâ”€â”€ State: shortlist, filters, selectedOpportunity, agentChat
â”‚   â”œâ”€â”€ useEffect: fetch API data on mount
â”‚   â””â”€â”€ useMemo: filteredOpportunities
â”‚
â”œâ”€â”€ Components
â”‚   â”œâ”€â”€ Header               # Logo + pipeline status
â”‚   â”œâ”€â”€ OpportunityCard       # Carte dans la liste
â”‚   â”œâ”€â”€ OpportunityDetail     # Panneau dÃ©tail (sticky)
â”‚   â”œâ”€â”€ ScoreRing             # Cercle SVG score
â”‚   â”œâ”€â”€ UrgencyBadge          # Badge urgence colorÃ©
â”‚   â””â”€â”€ AgentChat             # Modal chat IA
â”‚
â”œâ”€â”€ Lib
â”‚   â”œâ”€â”€ api.ts                # Client REST (snakeâ†’camelCase transform)
â”‚   â”œâ”€â”€ format.ts             # Formatters (prix, dates, nombres)
â”‚   â””â”€â”€ mockData.ts           # DonnÃ©es demo (fallback)
â”‚
â””â”€â”€ Types
    â””â”€â”€ opportunity.ts        # Interfaces TypeScript
```

### 8.2 Flux de donnÃ©es frontend

```
mount â†’ useEffect
  â”œâ”€â”€ api.getShortlist({ maxItems: 10 })  â†’  /api/shortlist?max_items=10
  â””â”€â”€ api.getPipelineStatus()              â†’  /api/pipeline/status
      â”‚
      â–¼ SuccÃ¨s â†’ dataSource='api', bandeau vert "ConnectÃ©"
      â–¼ Erreur â†’ dataSource='mock', bandeau jaune "Mode dÃ©mo"
      â”‚
      â–¼ shortlistData â†’ filteredOpportunities (useMemo)
      â”‚
      â–¼ Rendu: OpportunityCard[] + filtres + export CSV
```

### 8.3 Design System (Tailwind)

| Token | Couleur | Usage |
|-------|---------|-------|
| primary-50..900 | Bleu | Boutons, liens, sÃ©lection |
| critical | #dc2626 | Urgence critique |
| urgent | #f97316 | Urgence haute |
| active | #eab308 | FenÃªtre active |
| standard | #22c55e | Temps disponible |
| extended | #6b7280 | Pas d'urgence |

### 8.4 Proxy API

```javascript
// next.config.js
rewrites: [{
  source: '/api/:path*',
  destination: 'http://localhost:8000/api/:path*'
}]
```

---

## 9. Base de donnÃ©es

### 9.1 Infrastructure

- **HÃ©bergement** : Railway (PostgreSQL 17.7 managÃ©)
- **Endpoint** : `maglev.proxy.rlwy.net:41051/railway`
- **Extensions** : `pg_trgm` (trigram search), `btree_gin` (multi-index)
- **PAS disponible** : TimescaleDB, pgvector (adaptations faites)

### 9.2 Tables principales

```sql
-- 17 tables au total

asins                    -- Catalogue produits (PK: asin VARCHAR(10))
asin_snapshots           -- SÃ©ries temporelles prix/BSR/stock (PK: asin, captured_at)
price_events             -- Ã‰vÃ©nements prix (>5% variation)
bsr_events               -- Ã‰vÃ©nements BSR (>20% variation)
stock_events             -- Ã‰vÃ©nements stock (transitions)
reviews                  -- Reviews Amazon individuelles
review_analysis          -- Analyse NLP des reviews
opportunities            -- OpportunitÃ©s dÃ©tectÃ©es
pipeline_runs            -- Historique des runs (mÃ©triques, DQ gates)
opportunity_artifacts    -- Snapshots scoring immutables (audit)
shortlist_snapshots      -- Historique shortlist (hysteresis)
system_metrics           -- MÃ©triques systÃ¨me
rag_documents            -- Documents knowledge base
rag_chunks               -- Chunks avec embeddings (JSONB)
rag_citations            -- TraÃ§abilitÃ© utilisation chunks
```

### 9.3 SchÃ©ma des tables clÃ©s

#### asins (catalogue produits)
```sql
asin VARCHAR(10) PRIMARY KEY,
title TEXT,              -- NULL pour ASINs morts/dÃ©listÃ©s (migration 004)
brand VARCHAR(255),
category_id BIGINT,
category_path TEXT[],
is_active BOOLEAN DEFAULT TRUE,
tracking_priority INTEGER DEFAULT 5,
last_seen_at TIMESTAMPTZ, -- DerniÃ¨re apparition dans une rÃ©ponse Keepa
-- + 20 autres colonnes (dimensions, images, badges...)
```

#### asin_snapshots (sÃ©ries temporelles)
```sql
PRIMARY KEY (asin, captured_at),
price_current DECIMAL(10,2),
bsr_primary INTEGER,
stock_status stock_status,
rating_average DECIMAL(2,1),
review_count INTEGER,
-- Deltas calculÃ©s par trigger
price_delta DECIMAL(10,2),
price_delta_percent DECIMAL(5,2),
bsr_delta INTEGER,
bsr_delta_percent DECIMAL(5,2)
```

#### opportunity_artifacts (scoring immutable)
```sql
artifact_id UUID PRIMARY KEY,
run_id UUID REFERENCES pipeline_runs,
asin VARCHAR(10), rank INTEGER,
final_score INTEGER, base_score DECIMAL(5,4), time_multiplier DECIMAL(4,3),
component_scores JSONB, time_pressure_factors JSONB,
thesis TEXT, action_recommendation TEXT,
estimated_monthly_profit DECIMAL(12,2),
estimated_annual_value DECIMAL(12,2),
risk_adjusted_value DECIMAL(12,2),
window_days INTEGER, urgency_level VARCHAR(20),
amazon_price DECIMAL(10,2), review_count INTEGER, rating DECIMAL(2,1), bsr_primary INTEGER
```

#### pipeline_runs (audit trail)
```sql
run_id UUID PRIMARY KEY,
status pipeline_run_status,  -- running/completed/degraded/failed
asins_total INTEGER, asins_ok INTEGER, asins_failed INTEGER,
duration_total_ms INTEGER,
keepa_tokens_used INTEGER,
-- Data Quality Gates
dq_price_missing_pct DECIMAL(5,2),
dq_bsr_missing_pct DECIMAL(5,2),
dq_review_missing_pct DECIMAL(5,2),
dq_passed BOOLEAN,
error_rate DECIMAL(5,4),
error_budget_breached BOOLEAN,
shortlist_frozen BOOLEAN,
config_snapshot JSONB
```

### 9.4 Triggers (Ã©vÃ©nements automatiques)

| Trigger | Table | Condition | Action |
|---------|-------|-----------|--------|
| `trg_calculate_deltas` | asin_snapshots | BEFORE INSERT | Calcule price_delta, bsr_delta vs snapshot prÃ©cÃ©dent |
| `trg_generate_price_events` | asin_snapshots | AFTER INSERT | CrÃ©e price_event si \|delta\| â‰¥ 5% |
| `trg_generate_bsr_events` | asin_snapshots | AFTER INSERT | CrÃ©e bsr_event si \|delta\| â‰¥ 20% ou â‰¥ 10k positions |
| `trg_generate_stock_events` | asin_snapshots | AFTER INSERT | CrÃ©e stock_event sur changement de statut |

Tous avec `ON CONFLICT DO NOTHING` pour idempotence.

### 9.5 Vues matÃ©rialisÃ©es

| Vue | RafraÃ®chissement | DonnÃ©es |
|-----|-----------------|---------|
| `mv_latest_snapshots` | AprÃ¨s chaque run | Dernier snapshot par ASIN |
| `mv_asin_stats_7d` | AprÃ¨s chaque run | AgrÃ©gations 7 jours |
| `mv_asin_stats_30d` | AprÃ¨s chaque run | AgrÃ©gations 30j + volatilitÃ© + trend |
| `mv_review_sentiment` | AprÃ¨s chaque run | Sentiment reviews 90j |

### 9.6 Indexes (92+)

```
-- Recherche texte
idx_asins_title_trgm (title gin_trgm_ops)
idx_reviews_content_trgm (body gin_trgm_ops)

-- SÃ©ries temporelles
idx_snapshots_asin_time (asin, captured_at DESC)
idx_*_events_brin (detected_at USING BRIN)

-- Performance dashboard
idx_snapshots_dashboard_cover (asin, captured_at DESC)
  INCLUDE (price_current, bsr_primary, stock_status, rating_average, review_count)

-- DÃ©duplication events
idx_*_events_dedup (asin, snapshot_before_at, snapshot_after_at) UNIQUE
```

### 9.7 Enums PostgreSQL

```sql
stock_status:       in_stock | low_stock | out_of_stock | back_ordered | unknown
fulfillment_type:   fba | fbm | amazon | unknown
event_severity:     low | medium | high | critical
movement_direction: up | down | stable
opportunity_status: new | reviewing | validated | acted | archived | false_positive
opportunity_type:   price_drop | bsr_surge | stock_out_competitor | ...
sentiment_type:     very_negative | negative | neutral | positive | very_positive
pipeline_run_status: running | completed | degraded | failed | cancelled
```

---

## 10. Pipeline d'ingestion

### 10.1 CLI (run_controlled.py)

```bash
python scripts/run_controlled.py \
  --max-asins 100 \
  --freeze \
  -v \
  --log-file scripts/run1_audit.log
```

| Argument | Description | DÃ©faut |
|----------|-------------|--------|
| `--max-asins N` | Max ASINs Ã  traiter | 100 |
| `--freeze` | Mode observation (pas de promotion shortlist) | True |
| `--no-freeze` | DÃ©sactive freeze | False |
| `--skip-discovery` | Utilise ASINs existants en DB | False |
| `--asins A,B,C` | ASINs explicites | None |
| `-v, --verbose` | Logs debug | False |
| `--log-file PATH` | Log dans fichier | None |

### 10.2 Phases d'exÃ©cution

```
Phase 0: PRE-FLIGHT
  â”œâ”€ CrÃ©er pipeline_run en DB
  â”œâ”€ Charger configuration
  â”œâ”€ VÃ©rifier connexion Keepa (tokens)
  â””â”€ Initialiser scorer

Phase 1: INGESTION CONTRÃ”LÃ‰E
  Step 1: Discovery       â†’ best_sellers_query (10k ASINs, ~5 tokens)
  Step 2: Filtering       â†’ Filtre fraÃ®cheur + cap max_asins
  Step 3: Fetch           â†’ product_data batch (100 ASINs, ~200 tokens)
  Step 4: DB Insert       â†’ upsert metadata + insert snapshots (triggers!)
  Step 5: Data Quality    â†’ % manquant prix/BSR/reviews, seuil 30%
  Step 6: Scoring         â†’ EconomicScorer pour chaque produit
  Step 6b: Artifacts      â†’ Sauvegarde scores dans opportunity_artifacts
  Step 7: Refresh Views   â†’ REFRESH MATERIALIZED VIEW CONCURRENTLY

Phase 1b: RESULTS & AUDIT
  â”œâ”€ Update pipeline_run (status, mÃ©triques, DQ gates)
  â”œâ”€ Print top 10 + distribution scores
  â”œâ”€ Save audit JSON + opportunities JSON
  â””â”€ Print timing breakdown
```

### 10.3 Budget tokens Keepa

```
Plan actuel:        21 tokens/min refill rate
Bucket capacity:    ~200 tokens (configurable via KEEPA_TOKENS_PER_MINUTE)
Discovery:          ~5 tokens
100 ASINs:          ~200 tokens (2/ASIN)
Total Run 1:        ~205 tokens

Si bucket plein (200) â†’ run instantanÃ© (~25s rÃ©seau)
Si bucket vide (0)   â†’ ~205/21 = ~10 min d'attente avant run
```

**Distinction importante** :

| Concept | Valeur | Source |
|---------|--------|--------|
| `KEEPA_TOKENS_PER_MINUTE` (.env) | 200 | CapacitÃ© max du bucket local (rate limiter) |
| Refill rate rÃ©el | 21 tokens/min | Contrat Keepa, synchronisÃ© depuis les rÃ©ponses API |
| `tokens_left` (runtime) | 0â€“200 | Balance temps rÃ©el, dÃ©crÃ©mentÃ©e Ã  chaque appel |

Le client Keepa synchronise `tokens_left` et `refill_rate` depuis chaque rÃ©ponse API Keepa. Le rate limiter local utilise ces valeurs pour dÃ©cider quand faire la prochaine requÃªte.


---

## 11. DÃ©tection d'Ã©vÃ©nements

### 11.1 Types d'Ã©vÃ©nements

| Type | Seuil dÃ©clencheur | Signification |
|------|-------------------|--------------|
| `SUPPLY_SHOCK` | Stockout dÃ©tectÃ© | Demande non satisfaite |
| `COMPETITOR_COLLAPSE` | Vendeur majeur sorti | Parts Ã  capturer |
| `QUALITY_DECAY` | Reviews nÃ©gatifs en hausse | OpportunitÃ© diffÃ©renciation |
| `DEMAND_SURGE` | BSR en forte amÃ©lioration | Demande croissante |
| `PRICING_ANOMALY` | Prix hors norme | Arbitrage possible |
| `SEASONALITY_SIGNAL` | Pattern saisonnier | FenÃªtre timing |

### 11.2 GÃ©nÃ©ration automatique (triggers DB)

Les triggers sur `asin_snapshots` gÃ©nÃ¨rent automatiquement :
- **price_events** : quand |price_delta_percent| â‰¥ 5%
- **bsr_events** : quand |bsr_delta_percent| â‰¥ 20% ou |bsr_delta| â‰¥ 10k
- **stock_events** : sur tout changement de stock_status

SÃ©vÃ©ritÃ© auto-calculÃ©e : critical â†’ high â†’ medium â†’ low

---

## 11bis. Review Intelligence (Voice of Customer)

### Objectif

Transformer les avis Amazon en **spÃ©cifications produit actionnables** â€” pas du sentiment dÃ©coratif. RÃ©pondre Ã  la question que le scoring seul ne couvre pas : **"Comment battre le produit en place ?"**

### Architecture

```
reviews (DB table, Ã  remplir)
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                             â–¼
ReviewSignalExtractor          (Phase 2: LLM batch)
 (dÃ©terministe, lexique)        src/ai/review_analyzer.py
    â”‚                             â”‚
    â–¼                             â–¼
DefectSignal[]                 FeatureRequest[]
    â”‚                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
    ReviewInsightAggregator
               â”‚
               â–¼
    ProductImprovementProfile
    (improvement_score 0-1)
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼          â–¼           â–¼
 ranking    thesis      agents
 bonus     fragment    sourcing
```

### Pipeline d'extraction

| Ã‰tape | MÃ©thode | CoÃ»t | Dans le run principal ? |
|-------|---------|------|----------------------|
| **A. Filtrage** | rating â‰¤ 3 + body non vide | 0 | Oui |
| **B. Extraction dÃ©fauts** | Lexique 9 types Ã— ~90 keywords | 0 | Oui |
| **C. Extraction "I wish"** | 6 regex patterns | 0 | Oui |
| **D. AgrÃ©gation** | Profil par ASIN | 0 | Oui |
| **E. LLM "I wish" sÃ©mantique** | Claude/OpenAI batch | $$$ | **Non** â€” job sÃ©parÃ© |

### Lexique dÃ©fauts (Car Phone Mounts)

| Type | Keywords | Poids sÃ©vÃ©ritÃ© |
|------|----------|---------------|
| `mechanical_failure` | broke, snapped, cracked, fell apart... | 0.90 |
| `poor_grip` | slips, falls off, doesn't hold, loose... | 0.85 |
| `durability` | after a month, didn't last, adhesive wore off... | 0.75 |
| `compatibility_issue` | doesn't fit, case too thick, blocks camera... | 0.70 |
| `heat_issue` | overheats, gets hot, blocks airflow... | 0.65 |
| `installation_issue` | hard to install, suction doesn't hold... | 0.60 |
| `vibration_noise` | vibrates, rattles, wobbles... | 0.55 |
| `material_quality` | cheap plastic, feels flimsy, creaks... | 0.50 |
| `size_fit` | too bulky, blocks view, in the way... | 0.40 |

### Formule improvement_score

```python
# severity = base_weight Ã— frequency_factor (capped at 1.0)
# frequency_factor = min(1.0, defect_freq / negative_reviews Ã— 2)

defect_score = weighted_avg(top_5_severity) Ã— (0.5 + 0.5 Ã— coverage)
wish_bonus = min(0.2, count(wishes with 3+ mentions) Ã— 0.1)
improvement_score = min(1.0, defect_score + wish_bonus)
```

| Score | InterprÃ©tation |
|-------|---------------|
| > 0.7 | Forte opportunitÃ© d'amÃ©lioration â€” dÃ©fauts clairs et corrigeables |
| 0.4â€“0.7 | AmÃ©lioration possible â€” diffÃ©renciation modÃ©rÃ©e |
| < 0.4 | Peu de marge de diffÃ©renciation par les reviews |

### Connexion au systÃ¨me existant

| Composant | Utilisation de improvement_score |
|-----------|--------------------------------|
| **Ranking** | `rank_score += improvement_score Ã— 0.2 Ã— risk_adjusted_value` (bonus, PAS dans base_score) |
| **ThÃ¨se Ã©conomique** | Fragment auto-gÃ©nÃ©rÃ© : "43% des avis nÃ©gatifs mentionnent 'poor_grip'" |
| **Agent Sourcing** | Checklist auto : "test suction force", "compatibilitÃ© iPhone Pro Max + coque" |
| **Agent Analyst** | "Voici les 3 dÃ©fauts majeurs Ã  corriger pour battre ce produit" |

### RÃ¨gle de respect du gap_score (15 max)

L'improvement_score **ne modifie PAS** le gap_score du base_score.
Il agit comme un **bonus de ranking** sur le `rank_score` (aprÃ¨s calcul du score final).
Cela respecte le plafond de 15 points du composant gap.

### Tables SQL (migration 005)

| Table | RÃ´le |
|-------|------|
| `review_defects` | DÃ©fauts extraits par ASIN (dÃ©terministe) |
| `review_feature_requests` | Features manquantes (regex V1, LLM V2) |
| `review_improvement_profiles` | Profil agrÃ©gÃ© par ASIN + run (UNIQUE) |

### Module Python

```
src/reviews/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ review_models.py       # DefectSignal, FeatureRequest, ProductImprovementProfile
â”œâ”€â”€ review_signals.py      # ReviewSignalExtractor (lexique + regex)
â””â”€â”€ review_insights.py     # ReviewInsightAggregator (profil + DB save)
```

### Backfill Reviews

La table `reviews` se remplit via `scripts/run_reviews_backfill.py` â€” job **sÃ©parÃ©** du pipeline principal.

**Sources supportÃ©es** :
| Source | Commande | Usage |
|--------|----------|-------|
| CSV import | `--source csv --csv-file data/reviews.csv` | Testing, donnÃ©es tierces |
| Playwright | `--source playwright --top-n 20` | Headless Chromium (anti-bot) |

**NOT Keepa** : l'API Keepa ne fournit que des mÃ©triques agrÃ©gÃ©es (count, rating, historique) â€” pas le texte individuel des reviews.

**Options CLI** :
```bash
python scripts/run_reviews_backfill.py --top-n 20                    # top 20 ASINs
python scripts/run_reviews_backfill.py --asins B08L5TNJHG,B0F4MSXW3J  # ASINs spÃ©cifiques
python scripts/run_reviews_backfill.py --source csv --csv-file data/reviews_export.csv
python scripts/run_reviews_backfill.py --dry-run                     # preview sans fetch
```

**Garde-fous** :
- `--max-reviews-per-asin 200` : cap par ASIN
- `--max-total 5000` : cap global par run
- `--freshness-hours 168` : skip si reviews < 7 jours (incrÃ©mental)
- Idempotent : `ON CONFLICT (review_id) DO UPDATE` (dedup natif)
- Per-ASIN error handling : un ASIN en Ã©chec ne casse pas le run

**Post-backfill** : lance automatiquement Review Intelligence (Step 6c) sur les ASINs backfillÃ©s. Le pipeline principal (`run_controlled.py`) active aussi Step 6c dÃ¨s que `reviews` n'est plus vide.

### QualitÃ© Reviews (mÃ©triques backfill)

| MÃ©trique | Description |
|----------|-------------|
| `reviews_fetched` | Total reviews rÃ©cupÃ©rÃ©es |
| `reviews_inserted` | Nouvelles reviews insÃ©rÃ©es |
| `reviews_updated` | Reviews existantes mises Ã  jour |
| `reviews_duplicate_pct` | % de doublons (updated/fetched) |
| `asins_failed` | ASINs en Ã©chec (0 reviews) |
| `status` | `completed` / `degraded` / `failed` |

### defect_type Enum (Postgres)

Migration 006 : la colonne `review_defects.defect_type` est maintenant un **enum Postgres** (`defect_type_enum`) au lieu de TEXT libre. EmpÃªche le drift de nomenclature.

```sql
CREATE TYPE defect_type_enum AS ENUM (
    'mechanical_failure', 'poor_grip', 'installation_issue',
    'compatibility_issue', 'material_quality', 'vibration_noise',
    'heat_issue', 'size_fit', 'durability'
);
```

---

## 12. IA et Agents

### 12.1 Architecture agents

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Agent Chat (Frontend)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Discoveryâ”‚ â”‚Analyst â”‚ â”‚Sourcing  â”‚   â”‚
â”‚  â”‚   ðŸ”    â”‚ â”‚   ðŸ“Š   â”‚ â”‚   ðŸ­     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ POST /api/ai/agent/message
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Backend Agent Router           â”‚
â”‚  sessionId â†’ context â†’ agent â†’ response â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼         â–¼         â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Claude  â”‚ â”‚OpenAI â”‚ â”‚  RAG   â”‚
     â”‚(Thesis) â”‚ â”‚(Chat) â”‚ â”‚(Rules) â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 12.2 Types d'agents

| Agent | RÃ´le | DÃ©clencheur |
|-------|------|-------------|
| **Discovery** ðŸ” | Qualification d'opportunitÃ© | Bouton "Analyser avec l'IA" |
| **Analyst** ðŸ“Š | Analyse approfondie | Transition depuis Discovery |
| **Sourcing** ðŸ­ | Accompagnement fournisseurs | Bouton "Lancer le sourcing" |
| **Negotiator** ðŸ¤ | Aide Ã  la nÃ©gociation | Transition depuis Sourcing |

---

## 13. RAG (Retrieval-Augmented Generation)

### 13.1 Architecture RAG

```
Document â†’ Chunker (512 tokens) â†’ Embedder (JSONB) â†’ PostgreSQL
                                                        â”‚
Query â†’ Embedder â†’ Similarity Search â†’ Top-K chunks â†’ LLM + Context
```

### 13.2 Tables RAG

| Table | RÃ´le |
|-------|------|
| `rag_documents` | MÃ©tadonnÃ©es documents (type, domaine, dates) |
| `rag_chunks` | Chunks avec embeddings (JSONB, prÃªt pour pgvector) |
| `rag_citations` | TraÃ§abilitÃ© utilisation (session, agent, query) |

**Types de documents** : rules, ops, templates, memory

**Note** : Embeddings stockÃ©s en JSONB (pas pgvector). Migration vers `vector(1536)` prÃ©vue quand Railway supporte pgvector.

### 13.3 RÃ¨gles de sÃ©curitÃ© RAG (anti-bruit)

| RÃ¨gle | Valeur | Raison |
|-------|--------|--------|
| **Max chunks injectÃ©s** | K = 6 | Au-delÃ , le LLM dilue et invente |
| **Filtrage metadata obligatoire** | `doc_type`, `domain`, `marketplace`, `lang` | Ã‰vite d'injecter des rÃ¨gles FR dans un contexte US |
| **Citations obligatoires** | Chaque rÃ©ponse agent RAG â†’ `rag_citations` | TraÃ§abilitÃ©, auditabilitÃ©, dÃ©tection d'hallucination |
| **Score de similaritÃ© minimal** | > 0.7 (cosine) | Pas de chunks "vaguement liÃ©s" |
| **TTL des chunks** | Re-embedding si `updated_at` > 30j | Ã‰vite les donnÃ©es stales |

**Principe** : le RAG ne doit jamais donner au LLM plus de contexte que nÃ©cessaire. Un agent qui ne trouve pas de chunk pertinent doit rÃ©pondre "je n'ai pas d'information fiable" plutÃ´t qu'halluciner.

---

## 14. Orchestration & Monitoring

### 14.1 Pipeline quotidien

```python
# scripts/run_ingestion.py
Modes:
  --mode full           # Discover + filter + fetch
  --mode incremental    # Fetch ASINs existants uniquement
  --mode health         # VÃ©rification santÃ©
  --mode stats          # Afficher statistiques
```

### 14.2 Monitoring (pipeline_runs)

Chaque run enregistre :

| MÃ©trique | Description |
|----------|-------------|
| `duration_*_ms` | Timing par phase (ingestion, events, scoring, refresh) |
| `asins_total/ok/failed` | Compteurs d'exÃ©cution |
| `error_rate` | asins_failed / asins_total |
| `error_budget_breached` | error_rate â‰¥ 10% |
| `dq_*_missing_pct` | % donnÃ©es manquantes (prix, BSR, reviews) |
| `dq_passed` | Tous seuils DQ < 30% |
| `keepa_tokens_used` | Consommation API |
| `config_snapshot` | Configuration utilisÃ©e (JSONB) |

### 14.3 Maintenance

```sql
-- Nettoyage (cleanup_old_events)
DELETE FROM price_events WHERE detected_at < NOW() - retention;
DELETE FROM bsr_events WHERE detected_at < NOW() - retention;
DELETE FROM stock_events WHERE detected_at < NOW() - retention;
DELETE FROM opportunities WHERE status = 'archived' AND updated_at < NOW() - retention;
VACUUM ANALYZE;

-- Refresh views
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_latest_snapshots;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_asin_stats_7d;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_asin_stats_30d;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_review_sentiment;
```

### 14.4 SLO & Failure Modes

#### Service Level Objectives

| SLO | Cible | Mesure |
|-----|-------|--------|
| **DurÃ©e run** | < 5 min (100 ASINs) | `duration_total_ms` dans `pipeline_runs` |
| **Data Quality** | DQ pass obligatoire | `dq_passed = TRUE` (prix < 30%, BSR < 30%, reviews < 30% manquants) |
| **Error budget** | < 10% d'ASINs en erreur | `error_rate < 0.10` dans `pipeline_runs` |
| **DisponibilitÃ© API** | /shortlist rÃ©pond < 2s | Latence p99 (Ã  instrumenter) |
| **FraÃ®cheur donnÃ©es** | < 24h depuis dernier run OK | `pipeline_runs.completed_at` |

#### Failure Modes et rÃ©actions

| Statut pipeline | Condition | RÃ©action |
|----------------|-----------|----------|
| `completed` | DQ pass + error_rate < 10% | Shortlist mise Ã  jour, artifacts sauvÃ©s |
| `degraded` | DQ pass MAIS error_rate â‰¥ 10% | **Shortlist NON mise Ã  jour** (freeze automatique). Artifacts sauvÃ©s pour audit. Alerte Ã  dÃ©clencher |
| `failed` | Crash ou DQ fail | **Rien n'est Ã©crit**. Shortlist prÃ©cÃ©dente reste active. Alerte critique |
| `cancelled` | Interruption manuelle | Pas de consÃ©quence |

#### RÃ¨gle de protection shortlist

```
SI pipeline.status = 'degraded' OU 'failed'
   â†’ shortlist_frozen = TRUE
   â†’ L'API /shortlist sert les donnÃ©es du DERNIER run 'completed'
   â†’ Pas d'Ã©crasement des artifacts prÃ©cÃ©dents
```

Cette protection est dÃ©jÃ  implÃ©mentÃ©e via `error_budget_breached` et `shortlist_frozen` dans `pipeline_runs`.

---

## 15. Flux de donnÃ©es complet

```
                    KEEPA API
                       â”‚
                 â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                 â”‚  Discovery â”‚ (best_sellers_query)
                 â”‚  ~5 tokens â”‚
                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚ 10,000 ASINs
                       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Filter   â”‚ (fraÃ®cheur + cap)
                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚ 100 ASINs
                       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Fetch    â”‚ (product query)
                 â”‚ ~200 tok  â”‚
                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚ 100 ProductData
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼        â–¼        â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Upsert â”‚ â”‚Insertâ”‚ â”‚  Score   â”‚
         â”‚Metadataâ”‚ â”‚Snaps â”‚ â”‚(Economic)â”‚
         â”‚(asins) â”‚ â”‚      â”‚ â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚          â”‚
                 â”Œâ”€â”€â”€â”€â”€â”˜          â”‚
                 â”‚ TRIGGERS       â”‚
           â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”         â”‚
           â–¼     â–¼     â–¼         â”‚
        â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”    â”‚
        â”‚Priceâ”‚â”‚BSR â”‚â”‚Stockâ”‚    â”‚
        â”‚Eventâ”‚â”‚Evt â”‚â”‚Eventâ”‚    â”‚
        â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜    â”‚
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Artifacts   â”‚ (opportunity_artifacts)
              â”‚  100 scored  â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Refresh MVs  â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Audit JSON   â”‚ + pipeline_run DB
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ API /shortlistâ”‚ â†’ Frontend
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 16. SÃ©curitÃ© & Configuration

### 16.1 Variables d'environnement

```bash
# Keepa (requis)
KEEPA_API_KEY=<key>
KEEPA_TOKENS_PER_MINUTE=200  # Bucket capacity, NOT refill rate (refill = 21/min from plan)

# Database (requis)
DATABASE_HOST=maglev.proxy.rlwy.net
DATABASE_PORT=41051
DATABASE_NAME=railway
DATABASE_USER=postgres
DATABASE_PASSWORD=<password>
DATABASE_SSL_MODE=require

# Ingestion
INGESTION_CATEGORY_NODE_ID=7072562011  # Car Phone Mounts
INGESTION_BATCH_SIZE=100

# API
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### 16.2 Bonnes pratiques sÃ©curitÃ©

- `.env` non versionnÃ© (`.gitignore`)
- Connexion DB via SSL (require)
- Pas de credentials dans le code
- Pool de connexions (pas de connexions longues)
- Rate limiting Keepa cÃ´tÃ© client

---

## 17. Performance & Optimisations

### 17.1 Base de donnÃ©es

| Optimisation | Impact |
|-------------|--------|
| BRIN indexes sur timestamps events | RÃ©duction I/O sÃ©ries temporelles |
| Covering indexes (INCLUDE) | Ã‰vite heap access pour dashboard |
| Partial indexes (WHERE) | Cible les donnÃ©es actives |
| GIN indexes JSONB/arrays | Recherche rapide dans JSON |
| 4 parallel workers | Grandes tables |
| DÃ©duplication events (UNIQUE) | Idempotence pipeline |
| Mat views CONCURRENTLY | Pas de lock en lecture |

### 17.2 API

| Optimisation | Impact |
|-------------|--------|
| Connection pool (2-10) | RÃ©utilisation connexions |
| DB fallback â†’ mock data | Graceful degradation |
| Pydantic v2 (Rust core) | SÃ©rialisation rapide |

### 17.3 Pipeline

| Optimisation | Impact |
|-------------|--------|
| Batch 100 ASINs/requÃªte | 1 appel Keepa au lieu de 100 |
| Rate limiter intelligent | Ã‰vite token exhaustion |
| Exponential backoff | Retry robuste |
| Freeze mode | Pas d'Ã©criture shortlist |

### 17.4 Benchmarks Run 1

```
Discovery:    0.1s ( 0.6%)   â€” 10k ASINs
Filtering:    3.9s (15.7%)   â€” RequÃªte DB freshness
Fetch:       14.6s (59.0%)   â€” 100 ASINs Keepa
DB Insert:    1.1s ( 4.6%)   â€” 100 metadata + 100 snapshots
Scoring:      0.0s ( 0.1%)   â€” 100 scores
Refresh:      1.0s ( 3.9%)   â€” 4 mat views
TOTAL:       24.8s
```

---

## 18. DÃ©cisions architecturales

| DÃ©cision | Justification | Alternative rejetÃ©e |
|----------|--------------|-------------------|
| Scoring dÃ©terministe (pas de ML) | ExplicabilitÃ©, reproductibilitÃ©, pas de training data | ML/Neural scoring |
| Temps = multiplicateur | Un produit score 80 + fenÃªtre 14j > score 90 + fenÃªtre 180j | Temps comme composante additive |
| PostgreSQL pur (pas TimescaleDB) | Railway ne supporte pas l'extension | TimescaleDB hypertables |
| Embeddings en JSONB | pgvector non dispo, migration prÃ©vue | Stockage fichier |
| Triggers pour events | Automatique, atomique, pas d'oubli | GÃ©nÃ©ration cÃ´tÃ© application |
| Freeze mode par dÃ©faut | Observer avant d'agir, valider le scoring | Promotion directe |
| Mock data fallback (lecture seule) | Frontend consultable sans backend, mais actions dÃ©sactivÃ©es (sourcing, export, IA) avec banniÃ¨re DEMO explicite | Erreur si backend down |
| Lightweight scorer API | Ã‰vite dÃ©pendances lourdes (psycopg2) dans le hot path | Import scorer complet |
| run_controlled.py CLI | ContrÃ´le fin, audit trail, pas de scheduler complexe | Cron + orchestrateur |

---

## 19. RÃ©sultats Run 1

**Date** : 5 fÃ©vrier 2026
**DurÃ©e** : 24.8 secondes
**Status** : COMPLETED

| MÃ©trique | Valeur |
|----------|--------|
| ASINs dÃ©couverts | 10 000 |
| ASINs traitÃ©s | 100 |
| Products fetched | 100/100 (100%) |
| Snapshots insÃ©rÃ©s | 100 |
| Scores calculÃ©s | 100 |
| Erreurs | 0 (0%) |
| Tokens Keepa | 210 |
| DQ Gate | PASS |
| Prix manquants | 12% |
| Reviews manquants | 2% |

### Distribution des scores

```
  0-19:   0
 20-39:  24  ########################
 40-59:  69  #####################################################################
 60-79:   7  #######
80-100:   0
```

### Top 5 opportunitÃ©s

| # | Score | Window | Profit/an | ASIN | Produit |
|---|-------|--------|-----------|------|---------|
| 1 | 72 | 28j | $41,554 | B08L5TNJHG | Lamicall Car Phone Holder |
| 2 | 70 | 28j | $40,055 | B0F4MSXW3J | andobil MagSafe Mount |
| 3 | 68 | 28j | $38,556 | B0DFZXQFYZ | andobil Magnetic Holder |
| 4 | 66 | 45j | $26,297 | B0DGB3FFB6 | Lamicall Car Phone Holder |
| 5 | 63 | 45j | $29,496 | B0DHWPXNBZ | LISEN MagSafe Mount |

---

## 20. Roadmap

### Phase 2 : Auto-niche (planifiÃ©)

```
NicheScore = OpportunityDensity Ã— ExpectedValue Ã— TokenEfficiency
```

- `niche_catalog` : catalogue de niches avec mÃ©triques
- `niche_runs` : historique par niche
- `token_allocator` : allocation budgÃ©taire multi-niche
- 2-3 niches en production + 1 niche exploratoire
- Rotation automatique basÃ©e sur ROI tokens

### Phase 3 : Production

- Scheduler automatique (cron ou schedule)
- Alertes temps rÃ©el (WebSocket)
- Authentification utilisateur
- Dashboard analytics avancÃ©
- Export PDF/Excel
- Migration pgvector pour RAG

---

*Document gÃ©nÃ©rÃ© automatiquement Ã  partir de l'analyse du codebase Smartacus.*
